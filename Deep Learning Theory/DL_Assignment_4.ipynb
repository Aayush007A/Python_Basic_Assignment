{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef0a721",
   "metadata": {},
   "outputs": [],
   "source": [
    "********************************************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a387c1",
   "metadata": {},
   "source": [
    "## 1. How would you describe TensorFlow in a short sentence? What are its main features? Can you name other popular Deep Learning libraries?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a269573",
   "metadata": {},
   "source": [
    "TensorFlow is an open-source library developed by Google primarily for deep learning applications. It also supports traditional machine learning. TensorFlow was originally developed for large numerical computations without keeping deep learning in mind. However, it proved to be very useful for deep learning development as well, and therefore Google open-sourced it.\n",
    "\n",
    "TensorFlow accepts data in the form of multi-dimensional arrays of higher dimensions called tensors. Multi-dimensional arrays are very handy in handling large amounts of data.\n",
    "\n",
    "TensorFlow works on the basis of data flow graphs that have nodes and edges. As the execution mechanism is in the form of graphs, it is much easier to execute TensorFlow code in a distributed manner across a cluster of computers while using GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a94b77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "********************************************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2d1e97",
   "metadata": {},
   "source": [
    "## 2. Is TensorFlow a drop-in replacement for NumPy? What are the main differences between the two?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6e4709",
   "metadata": {},
   "source": [
    "I  think it may be worth adding a bit more of information, although it is easy to find about it just searching around a bit.\n",
    "\n",
    "NumPy and TensorFlow are actually very similar in many respects. Both are, essentially, array manipulation libraries, built around the concept of tensors (or nd-arrays, in NumPy terms). Originally, in TensorFlow 0.x and 1.x, there was only \"graph mode\", with all values being \"symbolic tensors\" that did not have a specific value until one was fed at a later point... It was a bit confusing and quite different from NumPy. Nowadays \"graph mode\" still exists but, for the most part, TensorFlow 2.x works in \"eager mode\", where each tensor has a specific value. This makes it more similar to NumPy, so the differences may seem subtle. So maybe we can draft a list with some of the most significant points.\n",
    "\n",
    "NumPy was developed as a full-fledged open source tensor algebra package for Python that could rival MATLAB and the likes. It is a Python library with a long history and plenty of functionality, either directly in it or built around it (see SciPy and different scikits). TensorFlow was developed by Google much more recently specifically for the purpose of building machine learning models (although you could use it for many other tasks), continuing the ideas from the (now discontinued) Theano library. Although TensorFlow is most commonly used with Python, it can be used in C/C++ and other languages too, which is important because it allows you to train a model in Python and then integrate it in an existing application written in another language.\n",
    "A main selling point of TensorFlow is that it can automatically differentiate computations. This is an essential feature for deep learning, that uses gradient-based optimization (backpropagation), and it means that you can pretty much just write whatever you want to compute and TensorFlow will figure out the gradients by itself. There are things like Autograd or JAX for NumPy, but they are not as powerful as TensorFlow automatic differentiation, which actually maintains a computation graph structure under the hood (the name \"TensorFlow\" refers to the tensors and their gradients \"flowing\" through the computation graph).\n",
    "TensorFlow offers GPU computation with CUDA out of the box. Again there are things like CuPy for NumPy, but it is not part of the library itself.\n",
    "TensorFlow integrates a lot more functionality that is not strictly array manipulation into the library itself, like image manipulation and common neural network utilities. NumPy tends to defer that kind of things to additional libraries like SciPy, making it more of an ecosystem and less monolithic. TensorFlow has some of that too, like TensorFlow Probability or TensorFlow Graphics, but it is not too developed yet.\n",
    "TensorFlow offers a bunch of useful stuff if you are doing machine learning, like training checkpoints, distributed training, TensorBoard, TensorFlow Serving, etc. It also integrates better (or at all) with inference platforms and standards like TensorRT, Google Coral, ONNX and that kind of stuff.\n",
    "NumPy generally integrates better with the \"traditional\" Python scientific stack, like Jupyter, Matplotlib, Pandas, dask, xarray, etc. There are pretty good libraries to do machine learning with NumPy too, like scikit-learn or Chainer, which are perfectly good if you only need to work in Python.\n",
    "TensorFlow and NumPy also work reasonably well together, specially in eager mode, where any TensorFlow tensor can be directly converted to a NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b297031",
   "metadata": {},
   "outputs": [],
   "source": [
    "********************************************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b80117",
   "metadata": {},
   "source": [
    "## 3. Do you get the same result with tf.range(10) and tf.constant(np.arange(10))?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18a28fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0 10]\n",
      "[ 0 10]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def main():\n",
    "\n",
    "    s = tf.constant(np.random.rand(20))\n",
    "    rate = 10\n",
    "    s1 = np.arange(0, tf.shape(s)[0], rate)\n",
    "    s2 = tf.range(0, tf.shape(s)[0], rate).numpy()\n",
    "\n",
    "    print(s1)\n",
    "    print(s2)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf2578b",
   "metadata": {},
   "outputs": [],
   "source": [
    "********************************************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47469d38",
   "metadata": {},
   "source": [
    "## 4. Can you name six other data structures available in TensorFlow, beyond regular tensors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d1c0d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Scalars or Rank-0 tensors:\n",
    "\n",
    "x = np.array(34)\n",
    "print(x)\n",
    "print(x.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04fa07ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34  4  7 21  8]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Vectors or Rank-1 tensors:\n",
    "\n",
    "y = np.array([34, 4, 7, 21, 8])\n",
    "print(y)\n",
    "print(y.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23d5886d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5 78  2 34  0]\n",
      " [ 6 79  3 35  1]\n",
      " [ 7 80  4 36  2]]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Matrices or Rank-2 tensors:\n",
    "\n",
    "z = np.array([[5, 78, 2, 34, 0],\n",
    "              [6, 79, 3, 35, 1],\n",
    "              [7, 80, 4, 36, 2]])\n",
    "print(z)\n",
    "print(z.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53ed3794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 5 78  2 34  0]\n",
      "  [ 6 79  3 35  1]\n",
      "  [ 7 80  4 36  2]]\n",
      "\n",
      " [[ 5 78  2 34  0]\n",
      "  [ 6 79  3 35  1]\n",
      "  [ 7 80  4 36  2]]\n",
      "\n",
      " [[ 5 78  2 34  0]\n",
      "  [ 6 79  3 35  1]\n",
      "  [ 7 80  4 36  2]]]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# Cube or Rank-3 tensors:\n",
    "\n",
    "w = np.array([[[5, 78, 2, 34, 0],\n",
    "               [6, 79, 3, 35, 1],\n",
    "               [7, 80, 4, 36, 2]],\n",
    "              [[5, 78, 2, 34, 0],\n",
    "               [6, 79, 3, 35, 1],\n",
    "               [7, 80, 4, 36, 2]],\n",
    "              [[5, 78, 2, 34, 0],\n",
    "               [6, 79, 3, 35, 1],\n",
    "               [7, 80, 4, 36, 2]]])\n",
    "print(w)\n",
    "print(w.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e584212",
   "metadata": {},
   "outputs": [],
   "source": [
    "********************************************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140cfaab",
   "metadata": {},
   "source": [
    "## 5. A custom loss function can be defined by writing a function or by subclassing the keras.losses.Loss class. When would you use each option?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ce6a97",
   "metadata": {},
   "source": [
    "## Probabilistic losses\n",
    "\n",
    "1. BinaryCrossentropy class\n",
    "2. CategoricalCrossentropy class\n",
    "3. SparseCategoricalCrossentropy class\n",
    "4. Poisson class\n",
    "5. binary_crossentropy function\n",
    "6. categorical_crossentropy function\n",
    "7. sparse_categorical_crossentropy function\n",
    "8. poisson function\n",
    "9. KLDivergence class\n",
    "10. kl_divergence function\n",
    "\n",
    "## Regression losses\n",
    "\n",
    "1. MeanSquaredError class\n",
    "2. MeanAbsoluteError class\n",
    "3. MeanAbsolutePercentageError class\n",
    "4. MeanSquaredLogarithmicError class\n",
    "5. CosineSimilarity class\n",
    "6. mean_squared_error function\n",
    "7. mean_absolute_error function\n",
    "8. mean_absolute_percentage_error function\n",
    "9. mean_squared_logarithmic_error function\n",
    "10. cosine_similarity function\n",
    "11. Huber class\n",
    "12. huber function\n",
    "13. LogCosh class\n",
    "14. log_cosh function\n",
    "\n",
    "## Hinge losses for \"maximum-margin\" classification\n",
    "\n",
    "1. Hinge class\n",
    "2. SquaredHinge class\n",
    "3. CategoricalHinge class\n",
    "4. hinge function\n",
    "5. squared_hinge function\n",
    "6. categorical_hinge function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df261b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "********************************************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b235b88a",
   "metadata": {},
   "source": [
    "## 6. Similarly, a custom metric can be defined in a function or a subclass of keras.metrics.Metric. When would you use each option?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d8a574",
   "metadata": {},
   "source": [
    "## Accuracy metrics\n",
    "\n",
    "1. Accuracy class\n",
    "2. BinaryAccuracy class\n",
    "3. CategoricalAccuracy class\n",
    "4. SparseCategoricalAccuracy class\n",
    "5. TopKCategoricalAccuracy class\n",
    "6. SparseTopKCategoricalAccuracy class\n",
    "7. Probabilistic metrics\n",
    "8. BinaryCrossentropy class\n",
    "9. CategoricalCrossentropy class\n",
    "10. SparseCategoricalCrossentropy class\n",
    "11. KLDivergence class\n",
    "12. Poisson class\n",
    "\n",
    "## Regression metrics\n",
    "\n",
    "1. MeanSquaredError class\n",
    "2. RootMeanSquaredError class\n",
    "3. MeanAbsoluteError class\n",
    "4. MeanAbsolutePercentageError class\n",
    "5. MeanSquaredLogarithmicError class\n",
    "6. CosineSimilarity class\n",
    "7. LogCoshError class\n",
    "\n",
    "## Classification metrics based on True/False positives & negatives\n",
    "\n",
    "1. AUC class\n",
    "2. Precision class\n",
    "3. Recall class\n",
    "4. TruePositives class\n",
    "5. TrueNegatives class\n",
    "6. FalsePositives class\n",
    "7. FalseNegatives class\n",
    "8. PrecisionAtRecall class\n",
    "9. SensitivityAtSpecificity class\n",
    "10. SpecificityAtSensitivity class\n",
    "\n",
    "## Image segmentation metrics\n",
    "\n",
    "1. MeanIoU class\n",
    "2. Hinge metrics for \"maximum-margin\" classification\n",
    "3. Hinge class\n",
    "4. SquaredHinge class\n",
    "5. CategoricalHinge class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0c759e",
   "metadata": {},
   "outputs": [],
   "source": [
    "********************************************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76510f69",
   "metadata": {},
   "source": [
    "## 7. When should you create a custom layer versus a custom model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7badf96c",
   "metadata": {},
   "source": [
    "If you are building a new model architecture using existing keras/tf layers then build a custom model. If you are implementing your own custom tensor operations with in a layer, then build a custom layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93f6300",
   "metadata": {},
   "outputs": [],
   "source": [
    "********************************************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72d4d8e",
   "metadata": {},
   "source": [
    "## 8. What are some use cases that require writing your own custom training loop?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d681dd",
   "metadata": {},
   "source": [
    "For people getting started with deep learning, the Keras toolbox has no equal. It has everything you need, with the confusing low-level stuff kept to a minimum. The API is very intuitive and makes you focus on the important bits of designing a network, allowing for fast experimentation without much hassle. As an example, the network used in this guide is specified and trained in less than 25 lines of Python code.\n",
    "\n",
    "There will come times, however, when the ease-of-use of basic Keras functions becomes limiting. Many more advanced neural network training schemes and loss functions become unnecessarily complicated to code up in native Keras. In this guide, I aim to show how the base Keras way of training a neural network can be broken up in its underlying parts, opening up the possibility to change each part as a user sees fit. I do not incorporate any of these custom parts in the example; this guide only aims to give you the tools to experiment more by yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3557cfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "********************************************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a742375",
   "metadata": {},
   "source": [
    "## 9. Can custom Keras components contain arbitrary Python code, or must they be convertible to TF Functions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b61b4fe",
   "metadata": {},
   "source": [
    "By default tensorflow 2.1 runs in eager mode which is useful for development and debugging. Performance can be boosted by wrapping your functions in `tf.function` which compiles a tensorflow graph which the framework can execute efficiently.\n",
    "\n",
    "There are several ways to wrap portions of your code as a `tf.function` . In the demonstrated toy example, the best performance was observed with the case when the entire training happened inside a tf.function.\n",
    "\n",
    "However in real world use case there are several factors at play — whether all of the dataset is in memory or streamed from disk / network , computational load of the model, whether gpu / multiple gpus are being used, how the shapes of your training data varies etc. One should experiment to figure how the `tf.function` can be used most efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8738a691",
   "metadata": {},
   "outputs": [],
   "source": [
    "********************************************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ae0c17",
   "metadata": {},
   "source": [
    "## 10. What are the main rules to respect if you want a function to be convertible to a TF Function?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8ffdab",
   "metadata": {},
   "source": [
    "A Function runs your program in a TensorFlow Graph. However, a tf.Graph cannot represent all the things that you'd write in an eager TensorFlow program. For instance, Python supports polymorphism, but tf.Graph requires its inputs to have a specified data type and dimension. Or you may perform side tasks like reading command-line arguments, raising an error, or working with a more complex Python object; none of these things can run in a tf.Graph.\n",
    "\n",
    "Function bridges this gap by separating your code in two stages:\n",
    "\n",
    "1) In the first stage, referred to as \"tracing\", Function creates a new tf.Graph. Python code runs normally, but all TensorFlow operations (like adding two Tensors) are deferred: they are captured by the tf.Graph and not run.\n",
    "\n",
    "2) In the second stage, a tf.Graph which contains everything that was deferred in the first stage is run. This stage is much faster than the tracing stage.\n",
    "\n",
    "Depending on its inputs, Function will not always run the first stage when it is called. See \"Rules of tracing\" below to get a better sense of how it makes that determination. Skipping the first stage and only executing the second stage is what gives you TensorFlow's high performance.\n",
    "\n",
    "When Function does decide to trace, the tracing stage is immediately followed by the second stage, so calling the Function both creates and runs the tf.Graph. Later you will see how you can run only the tracing stage with get_concrete_function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342292bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "********************************************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06f4468",
   "metadata": {},
   "source": [
    "## 11. When would you need to create a dynamic Keras model? How do you do that? Why not make all your models dynamic?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e59f90b",
   "metadata": {},
   "source": [
    "Keras is a neural network Application Programming Interface (API) for Python that is tightly integrated with TensorFlow, which is used to build machine learning models. Keras’ models offer a simple, user-friendly way to define a neural network, which will then be built for you by TensorFlow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7d511f",
   "metadata": {},
   "outputs": [],
   "source": [
    "********************************************************************************************************************************"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
